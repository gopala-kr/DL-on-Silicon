{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nCompile Tensorflow Models\n=========================\nThis article is an introductory tutorial to deploy tensorflow models with TVM.\n\nFor us to begin with, tensorflow python module is required to be installed.\n\nPlease refer to https://www.tensorflow.org/install\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# tvm and nnvm\nimport nnvm\nimport tvm\n\n# os and numpy\nimport numpy as np\nimport os.path\n\n# Tensorflow imports\nimport tensorflow as tf\nfrom tensorflow.core.framework import graph_pb2\nfrom tensorflow.python.framework import dtypes\nfrom tensorflow.python.framework import tensor_util\n\n# Tensorflow utility functions\nimport nnvm.testing.tf\n\n# Base location for model related files.\nrepo_base = 'https://github.com/dmlc/web-data/raw/master/tensorflow/models/InceptionV1/'\n\n# Test image\nimg_name = 'elephant-299.jpg'\nimage_url = os.path.join(repo_base, img_name)\n\n# InceptionV1 model protobuf\n# .. note::\n#\n#   protobuf should be exported with :any:`add_shapes=True` option.\n#   Could use https://github.com/dmlc/web-data/tree/master/tensorflow/scripts/tf-to-nnvm.py\n#   to add shapes for existing models.\n#\nmodel_name = 'classify_image_graph_def-with_shapes.pb'\nmodel_url = os.path.join(repo_base, model_name)\n\n# Image label map\nmap_proto = 'imagenet_2012_challenge_label_map_proto.pbtxt'\nmap_proto_url = os.path.join(repo_base, map_proto)\n\n# Human readable text for labels\nlable_map = 'imagenet_synset_to_human_label_map.txt'\nlable_map_url = os.path.join(repo_base, lable_map)\n\n# Target settings\n# Use these commented settings to build for cuda.\n#target = 'cuda'\n#target_host = 'llvm'\n#layout = \"NCHW\"\n#ctx = tvm.gpu(0)\ntarget = 'llvm'\ntarget_host = 'llvm'\nlayout = None\nctx = tvm.cpu(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Download required files\n-----------------------\nDownload files listed above.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from mxnet.gluon.utils import download\n\ndownload(image_url, img_name)\ndownload(model_url, model_name)\ndownload(map_proto_url, map_proto)\ndownload(lable_map_url, lable_map)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import model\n------------\nCreates tensorflow graph definition from protobuf file.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "with tf.gfile.FastGFile(os.path.join(\"./\", model_name), 'rb') as f:\n    graph_def = tf.GraphDef()\n    graph_def.ParseFromString(f.read())\n    graph = tf.import_graph_def(graph_def, name='')\n    # Call the utility to import the graph definition into default graph.\n    graph_def = nnvm.testing.tf.ProcessGraphDefParam(graph_def)\n    # Add shapes to the graph.\n    graph_def = nnvm.testing.tf.AddShapesToGraphDef('softmax')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Decode image\n------------\n<div class=\"alert alert-info\"><h4>Note</h4><p>tensorflow frontend import doesn't support preprocessing ops like JpegDecode\n  JpegDecode is bypassed (just return source node).\n  Hence we supply decoded frame to TVM instead.</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from PIL import Image\nimage = Image.open(img_name).resize((299, 299))\n\nx = np.array(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import the graph to NNVM\n------------------------\nImport tensorflow graph definition to nnvm.\n\nResults:\n  sym: nnvm graph for given tensorflow protobuf.\n  params: params converted from tensorflow params (tensor protobuf).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sym, params = nnvm.frontend.from_tensorflow(graph_def, layout=layout)\n\nprint (\"Tensorflow protobuf imported as nnvm graph\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NNVM Compilation\n----------------\nCompile the graph to llvm target with given input specification.\n\nResults:\n  graph: Final graph after compilation.\n  params: final params after compilation.\n  lib: target library which can be deployed on target with tvm runtime.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import nnvm.compiler\nshape_dict = {'DecodeJpeg/contents': x.shape}\ndtype_dict = {'DecodeJpeg/contents': 'uint8'}\ngraph, lib, params = nnvm.compiler.build(sym, shape=shape_dict, target=target, target_host=target_host, dtype=dtype_dict, params=params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Execute the portable graph on TVM\n---------------------------------\nNow we can try deploying the NNVM compiled model on target.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from tvm.contrib import graph_runtime\ndtype = 'uint8'\nm = graph_runtime.create(graph, lib, ctx)\n# set inputs\nm.set_input('DecodeJpeg/contents', tvm.nd.array(x.astype(dtype)))\nm.set_input(**params)\n# execute\nm.run()\n# get outputs\ntvm_output = m.get_output(0, tvm.nd.empty(((1, 1008)), 'float32'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Process the output\n------------------\nProcess the model output to human readable text for InceptionV1.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "predictions = tvm_output.asnumpy()\npredictions = np.squeeze(predictions)\n\n# Creates node ID --> English string lookup.\nnode_lookup = nnvm.testing.tf.NodeLookup(label_lookup_path=os.path.join(\"./\", map_proto),\n                                         uid_lookup_path=os.path.join(\"./\", lable_map))\n\n# Print top 5 predictions from TVM output.\ntop_k = predictions.argsort()[-5:][::-1]\nfor node_id in top_k:\n    human_string = node_lookup.id_to_string(node_id)\n    score = predictions[node_id]\n    print('%s (score = %.5f)' % (human_string, score))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Inference on tensorflow\n-----------------------\nRun the corresponding model on tensorflow\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def create_graph():\n    \"\"\"Creates a graph from saved GraphDef file and returns a saver.\"\"\"\n    # Creates graph from saved graph_def.pb.\n    with tf.gfile.FastGFile(model_name, 'rb') as f:\n        graph_def = tf.GraphDef()\n        graph_def.ParseFromString(f.read())\n        graph = tf.import_graph_def(graph_def, name='')\n        # Call the utility to import the graph definition into default graph.\n        graph_def = nnvm.testing.tf.ProcessGraphDefParam(graph_def)\n\ndef run_inference_on_image(image):\n    \"\"\"Runs inference on an image.\n\n    Parameters\n    ----------\n    image: String\n        Image file name.\n\n    Returns\n    -------\n        Nothing\n    \"\"\"\n    if not tf.gfile.Exists(image):\n        tf.logging.fatal('File does not exist %s', image)\n    image_data = tf.gfile.FastGFile(image, 'rb').read()\n\n    # Creates graph from saved GraphDef.\n    create_graph()\n\n    with tf.Session() as sess:\n        softmax_tensor = sess.graph.get_tensor_by_name('softmax:0')\n        predictions = sess.run(softmax_tensor,\n                               {'DecodeJpeg/contents:0': image_data})\n\n        predictions = np.squeeze(predictions)\n\n        # Creates node ID --> English string lookup.\n        node_lookup = nnvm.testing.tf.NodeLookup(label_lookup_path=os.path.join(\"./\", map_proto),\n                                                 uid_lookup_path=os.path.join(\"./\", lable_map))\n\n        # Print top 5 predictions from tensorflow.\n        top_k = predictions.argsort()[-5:][::-1]\n        print (\"===== TENSORFLOW RESULTS =======\")\n        for node_id in top_k:\n            human_string = node_lookup.id_to_string(node_id)\n            score = predictions[node_id]\n            print('%s (score = %.5f)' % (human_string, score))\n\nrun_inference_on_image (img_name)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}